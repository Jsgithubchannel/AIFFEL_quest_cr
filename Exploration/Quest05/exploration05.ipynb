{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adef8898",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1096f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151b81b",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60359f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n",
      "None\n",
      "\n",
      "0    5290\n",
      "1    3570\n",
      "2    2963\n",
      "Name: label, dtype: int64\n",
      "\n",
      "결측치 확인:\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/ChatbotData.csv')\n",
    "\n",
    "# 데이터 확인\n",
    "print(data.head())\n",
    "print()\n",
    "print(data.info())\n",
    "print()\n",
    "print(data['label'].value_counts())\n",
    "print(f\"\\n결측치 확인:\\n{data.isnull().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7621836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정제\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", text) # 특수문자 일부 제외하고 제거\n",
    "    return text\n",
    "\n",
    "# 'Q', 'A' 컬럼에 적용\n",
    "data['Q'] = data['Q'].apply(clean_text)\n",
    "data['A'] = data['A'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33640ab6",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cc262",
   "metadata": {},
   "source": [
    "## 토크나이저 학습용 코퍼스 생성 (질문 + 답변)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2119836b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "코퍼스 크기 (문장 수): 23646\n"
     ]
    }
   ],
   "source": [
    "corpus = data['Q'].tolist() + data['A'].tolist()\n",
    "print(f\"\\n코퍼스 크기 (문장 수): {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d984b0",
   "metadata": {},
   "source": [
    "## SubwordTextEncoder 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eed5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SubwordTextEncoder 구축 시작 (target_vocab_size=10000)...\n",
      "SubwordTextEncoder 구축 완료.\n",
      "단어 사전 크기 (실제): 10100\n"
     ]
    }
   ],
   "source": [
    "# target_vocab_size를 적절히 설정 (데이터셋 크기에 따라 조절)\n",
    "# 너무 작으면 UNK 토큰이 많아지고, 너무 크면 희소해질 수 있음\n",
    "target_vocab_size = 10000 # 예시 크기, 필요에 따라 조절\n",
    "\n",
    "print(f\"\\nSubwordTextEncoder 구축 시작 (target_vocab_size={target_vocab_size})...\")\n",
    "try:\n",
    "    # tfds.deprecated.text 사용\n",
    "    tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "        corpus, target_vocab_size=target_vocab_size\n",
    "    )\n",
    "    print(\"SubwordTextEncoder 구축 완료.\")\n",
    "    print(f\"단어 사전 크기 (실제): {tokenizer.vocab_size}\") # 목표 크기와 약간 다를 수 있음\n",
    "except AttributeError:\n",
    "    print(\"\\nError: tfds.deprecated.text.SubwordTextEncoder 를 찾을 수 없습니다.\")\n",
    "    print(\"tensorflow_datasets 버전이 너무 낮거나 높아서 경로가 변경되었을 수 있습니다.\")\n",
    "    print(\"최신 버전에서는 tensorflow_text 또는 Hugging Face Tokenizers 사용을 권장합니다.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\nSubwordTextEncoder 구축 중 오류 발생: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ffe1d",
   "metadata": {},
   "source": [
    "## 데이터 인코딩 및 디코딩 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aae0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 샘플 인코딩 (index=0) ---\n",
      "원본 질문 (Q): 12시 땡!\n",
      "인코딩된 Q: [6913, 3002, 4768, 9877]\n",
      "원본 답변 (A): 하루가 또 가네요.\n",
      "인코딩된 A: [3326, 66, 6893, 9890]\n",
      "\n",
      "--- 샘플 디코딩 ---\n",
      "디코딩된 Q: 12시 땡!\n",
      "디코딩된 A: 하루가 또 가네요.\n",
      "\n",
      "--- 서브워드 분리 결과 ---\n",
      "Q 서브워드: 12 | 시  | 땡 | !\n",
      "A 서브워드: 하루가  | 또  | 가네요 | .\n"
     ]
    }
   ],
   "source": [
    "sample_index = 0\n",
    "sample_q = data['Q'][sample_index]\n",
    "sample_a = data['A'][sample_index]\n",
    "\n",
    "# 인코딩\n",
    "encoded_q = tokenizer.encode(sample_q)\n",
    "encoded_a = tokenizer.encode(sample_a)\n",
    "\n",
    "print(f\"\\n--- 샘플 인코딩 (index={sample_index}) ---\")\n",
    "print(f\"원본 질문 (Q): {sample_q}\")\n",
    "print(f\"인코딩된 Q: {encoded_q}\")\n",
    "print(f\"원본 답변 (A): {sample_a}\")\n",
    "print(f\"인코딩된 A: {encoded_a}\")\n",
    "\n",
    "# 디코딩\n",
    "decoded_q = tokenizer.decode(encoded_q)\n",
    "decoded_a = tokenizer.decode(encoded_a)\n",
    "\n",
    "print(f\"\\n--- 샘플 디코딩 ---\")\n",
    "print(f\"디코딩된 Q: {decoded_q}\")\n",
    "print(f\"디코딩된 A: {decoded_a}\")\n",
    "\n",
    "\n",
    "# 서브워드 확인 (어떻게 분리되었는지)\n",
    "subwords_q = [tokenizer.decode([token]) for token in encoded_q]\n",
    "subwords_a = [tokenizer.decode([token]) for token in encoded_a]\n",
    "print(f\"\\n--- 서브워드 분리 결과 ---\")\n",
    "print(f\"Q 서브워드: {' | '.join(subwords_q)}\")\n",
    "print(f\"A 서브워드: {' | '.join(subwords_a)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c84d1",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b022a0e",
   "metadata": {},
   "source": [
    "## 포지셔널 인코딩\n",
    "- 순서 정보를 내재적으로 처리하지 못하는 트랜스포머 구조 특성상, 단어의 상대적 또는 절대적 위치를 모델에 알려주기 위해 임베딩 벡터에 포지셔널 인코딩 값을 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31cc15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    # position : 최대 시퀀스 길이\n",
    "    # d_model : 임베딩 차원\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis, :],\n",
    "                           d_model)\n",
    "    \n",
    "    # 배열의 짝수 인덱스에는 사인 함수 적용\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 코사인 함수 적용\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # 배치 차원 추가\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a1835",
   "metadata": {},
   "source": [
    "## 마스크 생성\n",
    "- 어텐션 매커니즘이 불필요한 부분에 집중하지 않도록 마스크 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b60332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8538940",
   "metadata": {},
   "source": [
    "## 스케일드 닷 프로덕트 어텐션\n",
    "- 트랜스포머 어텐션 핵심 계산 메커니즘\n",
    "- Q가 K와 유사도 내적을 계산하고, 이를 K의 차원 수 제곱근으로 나누어 스케일링\n",
    "- 이후 마스크 적용하고 Softmax로 어텐션 가중치를 구한 뒤, 가중치를 V에 곱하여 최종 어텐션 값 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9a8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    # Query와 Key의 내적 계산\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True) # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # 스케일링 (dk: Key의 마지막 차원 크기)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 마스크 적용 (마스크된 위치는 매우 작은 값으로 설정)\n",
    "    if mask is not None:\n",
    "        # mask 값이 1인 위치에 -1e9를 더해줌 (softmax 후 0에 가깝게 만듦)\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # Softmax로 어텐션 가중치 계산 (마지막 축 기준)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # Value와 어텐션 가중치 곱셈\n",
    "    output = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb519b7",
   "metadata": {},
   "source": [
    "## 멀티 헤드 어텐션\n",
    "- 한 번의 어텐션 대신 Q, K, V를 여러 개의 헤드로 나누어 각각 다른 관점에서 스케일드 닷 프로덕트 어텐션을 병렬로 수행\n",
    "- 각 헤드의 결과를 concat하고 마지막으로 Dense를 통과시켜 최종 어텐션 결과 얻음\n",
    "- 이를 통해 모델이 다양한 측면의 정보에 동시에 집중할 수 있게함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12f19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0 # d_model은 헤드 수로 나누어 떨어져야 함\n",
    "        self.depth = d_model // self.num_heads # 각 헤드의 차원\n",
    "\n",
    "        # Q, K, V 및 최종 출력을 위한 Dense 레이어\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, num_heads, seq_len, depth)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) # 헤드 차원을 앞으로\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        # 1. Q, K, V를 각각의 Dense 레이어 통과 (선형 변환)\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        # 2. 헤드 분할\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션 수행 (병렬)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        # scaled_attention: (batch_size, num_heads, seq_len_q, depth)\n",
    "\n",
    "        # 4. 헤드 연결 (Concatenate)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model)) # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        # 5. 최종 Dense 레이어 통과\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7ed6c",
   "metadata": {},
   "source": [
    "## 포인트 와이즈 피드 포워드 신경망\n",
    "- 각 위치마다 독립적으로 적용되는 간단한 완전 연결 신경망\n",
    "- 첫 번째 레이어는 활성화 함수 포함, 차원 확장했다가 두번째 레이어에서 다시 원래 차원으로 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc68818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    # d_model: 모델의 기본 차원\n",
    "    # dff: Feed Forward Network 내부 레이어의 차원 (보통 d_model * 4)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'), # 확장\n",
    "        tf.keras.layers.Dense(d_model)                 # 축소\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a3e9d",
   "metadata": {},
   "source": [
    "## 인코더 레이어\n",
    "- 첫 번째 서브 레이어: 멀티 헤드 어텐션 (Self-Attention, 즉 Q, K, V가 모두 이전 층의 출력) 수행 후 Add & Norm (잔차 연결 + 레이어 정규화).\n",
    "- 두 번째 서브 레이어: 포인트 와이즈 피드 포워드 신경망 수행 후 Add & Norm. Dropout은 각 서브 레이어의 출력에 적용되어 과적합을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8583fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        # 레이어 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask): # mask: 패딩 마스크\n",
    "        # 1. Multi-Head Self-Attention -> Dropout -> Add & Norm\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output) # 입력 x와 어텐션 출력을 더함 (Residual Connection)\n",
    "\n",
    "        # 2. Feed Forward Network -> Dropout -> Add & Norm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output) # 이전 결과 out1과 FFN 출력을 더함\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f7d57",
   "metadata": {},
   "source": [
    "## 디코더 레이어\n",
    "- 첫 번째 서브 레이어: Masked 멀티 헤드 어텐션 (Self-Attention, Look-ahead 마스크 사용) 수행 후 Add & Norm. 디코더가 이전에 생성한 단어들만 참조\n",
    "- 두 번째 서브 레이어: 멀티 헤드 어텐션 (Encoder-Decoder Attention). Query는 이전 서브 레이어의 출력, Key와 Value는 인코더의 최종 출력을 사용합니다. 인코더 출력 중 어떤 부분에 집중할지 결정. 이후 Add & Norm.\n",
    "- 세 번째 서브 레이어: 포인트 와이즈 피드 포워드 신경망 수행 후 Add & Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa3176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Masked Self-Attention (첫 번째 MHA)\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        # Encoder-Decoder Attention (두 번째 MHA)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # x: 디코더 입력 (이전 레이어 출력)\n",
    "        # enc_output: 인코더 최종 출력\n",
    "        # look_ahead_mask: 디코더 첫번째 MHA용 마스크 (Self-Attention Mask)\n",
    "        # padding_mask: 디코더 두번째 MHA용 마스크 (Encoder Output Padding Mask)\n",
    "\n",
    "        # 1. Masked Multi-Head Self-Attention -> Dropout -> Add & Norm\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) # Q, K, V 모두 x\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        # 2. Encoder-Decoder Attention -> Dropout -> Add & Norm\n",
    "        # Query: out1 (이전 결과), Key/Value: enc_output (인코더 출력)\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1) # 이전 결과 out1과 두번째 어텐션 결과 더함\n",
    "\n",
    "        # 3. Feed Forward Network -> Dropout -> Add & Norm\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2) # 이전 결과 out2와 FFN 출력 더함\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3dc03",
   "metadata": {},
   "source": [
    "## 인코더\n",
    "- 입력 시퀀스를 받아 임베딩과 포지셔널 인코딩을 적용한 후, 여러 개의 EncoderLayer를 순차적으로 통과시켜 입력 시퀀스의 최종 표현(representation) 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd439df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers # EncoderLayer 반복 횟수\n",
    "\n",
    "        # 임베딩 레이어\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        # 포지셔널 인코딩 값 (미리 계산)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        # num_layers 만큼 EncoderLayer 생성\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask): # x: 인코더 입력 시퀀스, mask: 패딩 마스크\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 1. 임베딩 + 포지셔널 인코딩\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # 임베딩 값 스케일링 (논문 방식)\n",
    "        x += self.pos_encoding[:, :seq_len, :] # 포지셔널 인코딩 더하기\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # 2. EncoderLayer 스택 통과\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x # 최종 인코더 출력 (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1887733",
   "metadata": {},
   "source": [
    "## 디코더\n",
    "- 타겟 시퀀스(보통 <SOS> 토큰으로 시작)를 받아 임베딩과 포지셔널 인코딩을 적용한 후, 여러 개의 DecoderLayer를 순차적으로 통과\n",
    "- 각 DecoderLayer는 인코더의 최종 출력(enc_output)을 참조하여 다음 단어를 예측하는 데 필요한 정보를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1322c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # x: 디코더 입력 시퀀스\n",
    "        # enc_output: 인코더 최종 출력\n",
    "        # look_ahead_mask: 디코더 첫번째 MHA용 마스크\n",
    "        # padding_mask: 디코더 두번째 MHA용 마스크\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {} # 각 레이어의 어텐션 가중치 저장 (시각화 등 활용)\n",
    "\n",
    "        # 1. 임베딩 + 포지셔널 인코딩\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # 2. DecoderLayer 스택 통과\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   look_ahead_mask, padding_mask)\n",
    "            # 어텐션 가중치 저장\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1 # Masked Self-Attention\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2 # Encoder-Decoder Attention\n",
    "\n",
    "        # 최종 디코더 출력 (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42131f08",
   "metadata": {},
   "source": [
    "## 트랜스포머 모델\n",
    "- 최종 트랜스포머 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de6a3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        # 인코더 초기화\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "        # 디코더 초기화\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "        # 최종 출력 레이어 (단어 사전 크기로 매핑)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        # inp: 인코더 입력 (질문)\n",
    "        # tar: 디코더 입력 (답변, <SOS> 시작)\n",
    "        # training: 학습 여부 (True/False)\n",
    "        # enc_padding_mask: 인코더 패딩 마스크\n",
    "        # look_ahead_mask: 디코더 첫번째 MHA용 마스크\n",
    "        # dec_padding_mask: 디코더 두번째 MHA용 마스크\n",
    "\n",
    "        # 1. 인코더 통과\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask) # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # 2. 디코더 통과\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask) # (batch_size, tar_seq_len, d_model)\n",
    "\n",
    "        # 3. 최종 선형 레이어 통과\n",
    "        final_output = self.final_layer(dec_output) # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights # 최종 로짓과 어텐션 가중치 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641fcf0",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef10a45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN: 10100, END_TOKEN: 10101\n",
      "MAX_LENGTH: 40, BATCH_SIZE: 64\n",
      "전체 데이터 인코딩 및 토큰 추가 중...\n",
      "인코딩 완료.\n",
      "\n",
      "패딩된 데이터 Shape:\n",
      "Encoder Input: (11823, 40)\n",
      "Decoder Input: (11823, 40)\n",
      "Decoder Target: (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비 (인코딩, 토큰 추가, 패딩)\n",
    "\n",
    "# 상수 정의 (★ 중요: 모델 생성 및 평가 시 동일하게 사용 ★)\n",
    "MAX_LENGTH = 40      # 예시 최대 길이, 데이터 분포 및 리소스 고려하여 결정\n",
    "BUFFER_SIZE = 20000  # 데이터 셔플링 버퍼 크기\n",
    "BATCH_SIZE = 64      # 배치 크기\n",
    "\n",
    "# SOS/EOS 토큰 정의\n",
    "START_TOKEN = tokenizer.vocab_size\n",
    "END_TOKEN = tokenizer.vocab_size + 1\n",
    "print(f\"START_TOKEN: {START_TOKEN}, END_TOKEN: {END_TOKEN}\")\n",
    "print(f\"MAX_LENGTH: {MAX_LENGTH}, BATCH_SIZE: {BATCH_SIZE}\")\n",
    "\n",
    "# 전체 데이터 인코딩 및 SOS/EOS 추가\n",
    "print(\"전체 데이터 인코딩 및 토큰 추가 중...\")\n",
    "try:\n",
    "    all_questions = [tokenizer.encode(q) for q in data['Q']]\n",
    "    all_answers = [tokenizer.encode(a) for a in data['A']]\n",
    "    print(\"인코딩 완료.\")\n",
    "\n",
    "    # 입력/출력 시퀀스 생성 및 패딩\n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        all_questions, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    decoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [[START_TOKEN] + a for a in all_answers], maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    decoder_target = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [a + [END_TOKEN] for a in all_answers], maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n패딩된 데이터 Shape:\")\n",
    "    print(f\"Encoder Input: {encoder_input.shape}\")\n",
    "    print(f\"Decoder Input: {decoder_input.shape}\")\n",
    "    print(f\"Decoder Target: {decoder_target.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n데이터 인코딩 또는 패딩 중 오류 발생: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cd7b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 데이터셋 크기: 10640\n",
      "검증 데이터셋 크기: 1183\n",
      "\n",
      "훈련 및 검증용 tf.data.Dataset 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터셋 분할 및 tf.data.Dataset 생성\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 훈련 세트와 검증 세트로 분할 (예: 90% 훈련, 10% 검증)\n",
    "enc_train, enc_val, dec_in_train, dec_in_val, dec_out_train, dec_out_val = train_test_split(\n",
    "    encoder_input, decoder_input, decoder_target, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n훈련 데이터셋 크기: {len(enc_train)}\")\n",
    "print(f\"검증 데이터셋 크기: {len(enc_val)}\")\n",
    "\n",
    "# tf.data.Dataset 객체 생성 (학습 효율성 향상)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': enc_train, 'dec_inputs': dec_in_train}, # 모델 입력은 딕셔너리 형태 권장\n",
    "    {'outputs': dec_out_train}                         # 모델 출력(타겟)도 딕셔너리 형태 권장\n",
    "))\n",
    "train_dataset = train_dataset.cache() # 데이터를 메모리에 캐싱하여 속도 향상 (메모리 부족 시 제거)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE) # 학습 중 다음 배치를 미리 로드\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': enc_val, 'dec_inputs': dec_in_val},\n",
    "    {'outputs': dec_out_val}\n",
    "))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(\"\\n훈련 및 검증용 tf.data.Dataset 생성 완료.\")\n",
    "# print(f\"훈련 데이터셋 샘플 (첫 배치): {next(iter(train_dataset))}\") # 데이터 형태 확인용 (선택적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bec15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformer 모델 인스턴스 생성 중...\n",
      "모델 인스턴스 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 인스턴스 생성\n",
    "\n",
    "# 하이퍼파라미터 설정 (★ 성능 위해 튜닝 필요 ★)\n",
    "NUM_LAYERS = 2       # 인코더/디코더 레이어 수 (낮으면 학습 빠름, 높으면 성능 기대)\n",
    "D_MODEL = 256        # 임베딩 및 모델 내부 벡터 차원\n",
    "NUM_HEADS = 8        # 멀티 헤드 어텐션 헤드 수 (D_MODEL의 약수여야 함)\n",
    "DFF = 512            # Feed Forward Network 내부 차원\n",
    "DROPOUT_RATE = 0.1   # 드롭아웃 비율\n",
    "\n",
    "# 어휘 사전 크기 (START_TOKEN, END_TOKEN 포함)\n",
    "INPUT_VOCAB_SIZE = target_vocab_size = START_TOKEN + 2 # tokenizer.vocab_size + 2\n",
    "\n",
    "print(\"\\nTransformer 모델 인스턴스 생성 중...\")\n",
    "# Step 4에서 정의한 Transformer 클래스 사용\n",
    "transformer = Transformer(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dff=DFF,\n",
    "    input_vocab_size=INPUT_VOCAB_SIZE,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    pe_input=MAX_LENGTH,  # 포지셔널 인코딩 최대 길이 (인코더)\n",
    "    pe_target=MAX_LENGTH, # 포지셔널 인코딩 최대 길이 (디코더)\n",
    "    rate=DROPOUT_RATE\n",
    ")\n",
    "print(\"모델 인스턴스 생성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d950373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 손실 함수, 옵티마이저, 평가지표 정의\n",
    "\n",
    "# 손실 함수 (패딩 마스킹 적용)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none') # 각 샘플별 손실 계산 후 평균내기 위해 reduction='none'\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # real: 실제 타겟값 (ID), shape=(batch, seq_len)\n",
    "    # pred: 모델 예측값 (logits), shape=(batch, seq_len, vocab_size)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # 실제 타겟값이 0 (패딩)인 위치는 False\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype) # 마스크 타입을 손실값 타입과 일치시킴\n",
    "    loss_ *= mask # 패딩 위치의 손실을 0으로 만듦\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask) # 실제 토큰(패딩 제외) 개수로 나누어 평균 손실 계산\n",
    "\n",
    "# 정확도 함수 (패딩 마스킹 적용)\n",
    "def accuracy_function(real, pred):\n",
    "    # 가장 높은 확률을 가진 예측 토큰 ID 추출\n",
    "    accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis=2), dtype=real.dtype))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # 패딩 제외 마스크\n",
    "    accuracies = tf.math.logical_and(mask, accuracies) # 패딩 아닌 위치 중 예측 맞은 것만 True\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    # 실제 토큰 수 대비 정확히 예측한 토큰 수의 비율 계산\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "# 학습률 스케줄 정의 (논문 참고: Warmup + Decay)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        # step이 warmup_steps보다 작으면 학습률 증가, 크면 감소\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 옵티마이저 정의\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c57d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤형 학습 시작 (EPOCHS=20)\n",
      "정보: 저장된 체크포인트가 없습니다. 처음부터 학습을 시작합니다.\n",
      "Epoch 1/20 Batch 0 Loss 9.2229 Accuracy 0.0000\n",
      "Epoch 1/20 Batch 100 Loss 8.8890 Accuracy 0.0988\n",
      "\n",
      "Epoch 1 완료:\n",
      "  훈련 손실: 8.6275 - 훈련 정확도: 0.1202\n",
      "  검증 손실: 7.9167 - 검증 정확도: 0.1536\n",
      "  소요 시간: 18.10 초\n",
      "  개선된 검증 손실(7.9167), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-1\n",
      "Epoch 2/20 Batch 0 Loss 7.9451 Accuracy 0.1582\n",
      "Epoch 2/20 Batch 100 Loss 7.4793 Accuracy 0.2600\n",
      "\n",
      "Epoch 2 완료:\n",
      "  훈련 손실: 7.1759 - 훈련 정확도: 0.2733\n",
      "  검증 손실: 6.4005 - 검증 정확도: 0.2997\n",
      "  소요 시간: 9.07 초\n",
      "  개선된 검증 손실(6.4005), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-2\n",
      "Epoch 3/20 Batch 0 Loss 6.2519 Accuracy 0.3181\n",
      "Epoch 3/20 Batch 100 Loss 6.1074 Accuracy 0.2968\n",
      "\n",
      "Epoch 3 완료:\n",
      "  훈련 손실: 5.9901 - 훈련 정확도: 0.2963\n",
      "  검증 손실: 5.6926 - 검증 정확도: 0.3028\n",
      "  소요 시간: 9.12 초\n",
      "  개선된 검증 손실(5.6926), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-3\n",
      "Epoch 4/20 Batch 0 Loss 5.6705 Accuracy 0.2927\n",
      "Epoch 4/20 Batch 100 Loss 5.5287 Accuracy 0.3061\n",
      "\n",
      "Epoch 4 완료:\n",
      "  훈련 손실: 5.4773 - 훈련 정확도: 0.3100\n",
      "  검증 손실: 5.3794 - 검증 정확도: 0.3240\n",
      "  소요 시간: 9.15 초\n",
      "  개선된 검증 손실(5.3794), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-4\n",
      "Epoch 5/20 Batch 0 Loss 5.2735 Accuracy 0.3143\n",
      "Epoch 5/20 Batch 100 Loss 5.1992 Accuracy 0.3246\n",
      "\n",
      "Epoch 5 완료:\n",
      "  훈련 손실: 5.1620 - 훈련 정확도: 0.3276\n",
      "  검증 손실: 5.1678 - 검증 정확도: 0.3333\n",
      "  소요 시간: 9.21 초\n",
      "  개선된 검증 손실(5.1678), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-5\n",
      "Epoch 6/20 Batch 0 Loss 5.0254 Accuracy 0.3231\n",
      "Epoch 6/20 Batch 100 Loss 4.8912 Accuracy 0.3405\n",
      "\n",
      "Epoch 6 완료:\n",
      "  훈련 손실: 4.8694 - 훈련 정확도: 0.3427\n",
      "  검증 손실: 4.9610 - 검증 정확도: 0.3504\n",
      "  소요 시간: 9.24 초\n",
      "  개선된 검증 손실(4.9610), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-6\n",
      "Epoch 7/20 Batch 0 Loss 4.6496 Accuracy 0.3486\n",
      "Epoch 7/20 Batch 100 Loss 4.5902 Accuracy 0.3613\n",
      "\n",
      "Epoch 7 완료:\n",
      "  훈련 손실: 4.5548 - 훈련 정확도: 0.3664\n",
      "  검증 손실: 4.7814 - 검증 정확도: 0.3686\n",
      "  소요 시간: 9.28 초\n",
      "  개선된 검증 손실(4.7814), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-7\n",
      "Epoch 8/20 Batch 0 Loss 4.1465 Accuracy 0.4424\n",
      "Epoch 8/20 Batch 100 Loss 4.2436 Accuracy 0.3936\n",
      "\n",
      "Epoch 8 완료:\n",
      "  훈련 손실: 4.2076 - 훈련 정확도: 0.3970\n",
      "  검증 손실: 4.5494 - 검증 정확도: 0.3933\n",
      "  소요 시간: 9.30 초\n",
      "  개선된 검증 손실(4.5494), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-8\n",
      "Epoch 9/20 Batch 0 Loss 3.9108 Accuracy 0.4207\n",
      "Epoch 9/20 Batch 100 Loss 3.8453 Accuracy 0.4353\n",
      "\n",
      "Epoch 9 완료:\n",
      "  훈련 손실: 3.8200 - 훈련 정확도: 0.4380\n",
      "  검증 손실: 4.3845 - 검증 정확도: 0.4121\n",
      "  소요 시간: 9.33 초\n",
      "  개선된 검증 손실(4.3845), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-9\n",
      "Epoch 10/20 Batch 0 Loss 3.4713 Accuracy 0.4939\n",
      "Epoch 10/20 Batch 100 Loss 3.4103 Accuracy 0.4877\n",
      "\n",
      "Epoch 10 완료:\n",
      "  훈련 손실: 3.3922 - 훈련 정확도: 0.4892\n",
      "  검증 손실: 4.1743 - 검증 정확도: 0.4376\n",
      "  소요 시간: 9.37 초\n",
      "  개선된 검증 손실(4.1743), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-10\n",
      "Epoch 11/20 Batch 0 Loss 2.9656 Accuracy 0.5374\n",
      "Epoch 11/20 Batch 100 Loss 2.9518 Accuracy 0.5437\n",
      "\n",
      "Epoch 11 완료:\n",
      "  훈련 손실: 2.9469 - 훈련 정확도: 0.5433\n",
      "  검증 손실: 4.1000 - 검증 정확도: 0.4466\n",
      "  소요 시간: 9.41 초\n",
      "  개선된 검증 손실(4.1000), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-11\n",
      "Epoch 12/20 Batch 0 Loss 2.4383 Accuracy 0.6039\n",
      "Epoch 12/20 Batch 100 Loss 2.4908 Accuracy 0.6042\n",
      "\n",
      "Epoch 12 완료:\n",
      "  훈련 손실: 2.4956 - 훈련 정확도: 0.6005\n",
      "  검증 손실: 3.9969 - 검증 정확도: 0.4714\n",
      "  소요 시간: 9.42 초\n",
      "  개선된 검증 손실(3.9969), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-12\n",
      "Epoch 13/20 Batch 0 Loss 1.8760 Accuracy 0.7206\n",
      "Epoch 13/20 Batch 100 Loss 2.0422 Accuracy 0.6658\n",
      "\n",
      "Epoch 13 완료:\n",
      "  훈련 손실: 2.0558 - 훈련 정확도: 0.6603\n",
      "  검증 손실: 3.9187 - 검증 정확도: 0.4896\n",
      "  소요 시간: 9.49 초\n",
      "  개선된 검증 손실(3.9187), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-13\n",
      "Epoch 14/20 Batch 0 Loss 1.7333 Accuracy 0.6856\n",
      "Epoch 14/20 Batch 100 Loss 1.6263 Accuracy 0.7234\n",
      "\n",
      "Epoch 14 완료:\n",
      "  훈련 손실: 1.6390 - 훈련 정확도: 0.7181\n",
      "  검증 손실: 3.8445 - 검증 정확도: 0.5094\n",
      "  소요 시간: 9.51 초\n",
      "  개선된 검증 손실(3.8445), 체크포인트 저장 완료: ./transformer_checkpoints/ckpt-14\n",
      "Epoch 15/20 Batch 0 Loss 1.1793 Accuracy 0.7922\n",
      "Epoch 15/20 Batch 100 Loss 1.2351 Accuracy 0.7829\n",
      "\n",
      "Epoch 15 완료:\n",
      "  훈련 손실: 1.2643 - 훈련 정확도: 0.7743\n",
      "  검증 손실: 3.8449 - 검증 정확도: 0.5217\n",
      "  소요 시간: 9.52 초\n",
      "  검증 손실 개선 없음 (카운터: 1/3)\n",
      "Epoch 16/20 Batch 0 Loss 0.9110 Accuracy 0.8391\n",
      "Epoch 16/20 Batch 100 Loss 0.9108 Accuracy 0.8403\n",
      "\n",
      "Epoch 16 완료:\n",
      "  훈련 손실: 0.9413 - 훈련 정확도: 0.8290\n",
      "  검증 손실: 3.8680 - 검증 정확도: 0.5421\n",
      "  소요 시간: 9.53 초\n",
      "  검증 손실 개선 없음 (카운터: 2/3)\n",
      "Epoch 17/20 Batch 0 Loss 0.5515 Accuracy 0.9150\n",
      "Epoch 17/20 Batch 100 Loss 0.6528 Accuracy 0.8854\n",
      "\n",
      "Epoch 17 완료:\n",
      "  훈련 손실: 0.6808 - 훈련 정확도: 0.8754\n",
      "  검증 손실: 3.8944 - 검증 정확도: 0.5544\n",
      "  소요 시간: 9.58 초\n",
      "  검증 손실 개선 없음 (카운터: 3/3)\n",
      "\n",
      "3 에폭 동안 검증 손실이 개선되지 않아 학습을 조기 종료합니다!\n",
      "\n",
      "맞춤형 학습 루프 완료.\n"
     ]
    }
   ],
   "source": [
    "# --- 모델 학습 (맞춤형 학습 루프) ---\n",
    "import time # 시간 측정을 위해 추가\n",
    "\n",
    "# 학습 관련 상수 확인 (이전 셀에서 정의됨)\n",
    "if 'EPOCHS' not in locals(): EPOCHS = 20 # 기본값 설정 (이전 셀 실행 권장)\n",
    "if 'checkpoint_dir' not in locals(): checkpoint_dir = './transformer_checkpoints' # 기본값\n",
    "# optimizer, loss_function, accuracy_function 등도 이전 셀에서 정의되어 있어야 함\n",
    "if 'optimizer' not in locals() or 'loss_function' not in locals() or 'accuracy_function' not in locals():\n",
    "    raise NameError(\"오류: optimizer, loss_function 또는 accuracy_function이 정의되지 않았습니다.\")\n",
    "\n",
    "print(f\"맞춤형 학습 시작 (EPOCHS={EPOCHS})\")\n",
    "\n",
    "# 학습/검증 과정에서의 평균 손실/정확도 추적용 Metric 객체\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy') # 에폭 평균 계산 위해 Mean 사용\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n",
    "\n",
    "# 체크포인트 관리자 (더 안정적인 저장/로드)\n",
    "# transformer와 optimizer 객체가 정의되어 있어야 함\n",
    "if 'transformer' in locals() and transformer is not None:\n",
    "    ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=3) # 최근 3개 체크포인트 유지\n",
    "\n",
    "    # 최신 체크포인트 복원 (학습 재개 시 유용)\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "        print(f'성공: 최신 체크포인트를 복원했습니다! 경로: {ckpt_manager.latest_checkpoint}')\n",
    "    else:\n",
    "        print(\"정보: 저장된 체크포인트가 없습니다. 처음부터 학습을 시작합니다.\")\n",
    "else:\n",
    "    print(\"경고: transformer 객체가 없어 체크포인트 관리를 건너뜁니다.\")\n",
    "    ckpt_manager = None # 체크포인트 관리 비활성화\n",
    "\n",
    "# 학습 스텝 함수 (tf.function으로 컴파일하여 속도 향상)\n",
    "# 이 함수들은 이전에 정의된 loss_function, accuracy_function, create_padding_mask, create_look_ahead_mask 사용\n",
    "@tf.function\n",
    "def train_step(inputs_dict, targets_dict):\n",
    "    # 데이터셋에서 입력 분리\n",
    "    enc_input = inputs_dict['inputs']  # 인코더 입력\n",
    "    dec_input = inputs_dict['dec_inputs'] # 디코더 입력 (<SOS> 시작)\n",
    "    targets = targets_dict['outputs']     # 실제 정답 (<EOS> 포함)\n",
    "\n",
    "    # 마스크 생성\n",
    "    enc_padding_mask = create_padding_mask(enc_input)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(dec_input)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(dec_input)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    dec_padding_mask = create_padding_mask(enc_input) # Enc-Dec 어텐션용 마스크\n",
    "\n",
    "    # 그래디언트 계산을 위한 컨텍스트\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 모델 정방향 실행 (training=True)\n",
    "        predictions, _ = transformer(enc_input,\n",
    "                                     dec_input,\n",
    "                                     True, # 학습 중이므로 True\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        # 손실 계산 (패딩 제외)\n",
    "        loss = loss_function(targets, predictions)\n",
    "\n",
    "    # 그래디언트 계산\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    # 옵티마이저로 가중치 업데이트\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    # 손실 및 정확도 기록 (에폭 평균 계산용)\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(targets, predictions))\n",
    "\n",
    "# 검증 스텝 함수 (tf.function으로 컴파일)\n",
    "@tf.function\n",
    "def val_step(inputs_dict, targets_dict):\n",
    "    enc_input = inputs_dict['inputs']\n",
    "    dec_input = inputs_dict['dec_inputs']\n",
    "    targets = targets_dict['outputs']\n",
    "\n",
    "    # 마스크 생성 (train_step과 동일)\n",
    "    enc_padding_mask = create_padding_mask(enc_input)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(dec_input)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(dec_input)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    dec_padding_mask = create_padding_mask(enc_input)\n",
    "\n",
    "    # 모델 예측 (training=False)\n",
    "    predictions, _ = transformer(enc_input,\n",
    "                                 dec_input,\n",
    "                                 False, # 검증 중이므로 False\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    # 손실 계산\n",
    "    loss = loss_function(targets, predictions)\n",
    "\n",
    "    # 손실 및 정확도 기록\n",
    "    val_loss(loss)\n",
    "    val_accuracy(accuracy_function(targets, predictions))\n",
    "\n",
    "\n",
    "# --- 맞춤형 학습 루프 시작 ---\n",
    "best_val_loss = float('inf') # 최고 검증 손실 기록용\n",
    "patience_counter = 0         # 조기 종료 카운터\n",
    "patience = 3                 # 조기 종료 기준 (예: 3 에폭 동안 개선 없을 시)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time() # 에폭 시작 시간 기록\n",
    "\n",
    "    # 각 에폭 시작 시 Metric 초기화\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "\n",
    "    # 훈련 데이터셋 루프 (train_dataset은 이전 셀에서 생성됨)\n",
    "    # train_dataset은 (inputs_dict, targets_dict) 형태의 배치를 반환\n",
    "    for (batch, (inputs_dict, targets_dict)) in enumerate(train_dataset):\n",
    "        train_step(inputs_dict, targets_dict) # 각 배치마다 학습 스텝 실행\n",
    "        # 진행 상황 출력 (예: 100 배치마다)\n",
    "        if batch % 100 == 0:\n",
    "             print(f'Epoch {epoch + 1}/{EPOCHS} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    # 검증 데이터셋 루프 (val_dataset은 이전 셀에서 생성됨)\n",
    "    for (batch, (inputs_dict, targets_dict)) in enumerate(val_dataset):\n",
    "        val_step(inputs_dict, targets_dict) # 각 배치마다 검증 스텝 실행\n",
    "\n",
    "    # 에폭 결과 출력\n",
    "    print(f'\\nEpoch {epoch + 1} 완료:')\n",
    "    print(f'  훈련 손실: {train_loss.result():.4f} - 훈련 정확도: {train_accuracy.result():.4f}')\n",
    "    print(f'  검증 손실: {val_loss.result():.4f} - 검증 정확도: {val_accuracy.result():.4f}')\n",
    "    print(f'  소요 시간: {time.time() - start_time:.2f} 초')\n",
    "\n",
    "    # 체크포인트 저장 및 조기 종료 확인\n",
    "    current_val_loss = val_loss.result()\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        if ckpt_manager: # 체크포인트 매니저가 있을 경우 저장\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'  개선된 검증 손실({best_val_loss:.4f}), 체크포인트 저장 완료: {ckpt_save_path}')\n",
    "        else:\n",
    "            print(f'  개선된 검증 손실({best_val_loss:.4f}), (체크포인트 매니저 없음)')\n",
    "        patience_counter = 0 # 개선되었으므로 카운터 초기화\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'  검증 손실 개선 없음 (카운터: {patience_counter}/{patience})')\n",
    "\n",
    "    # 조기 종료 조건 확인\n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\n{patience} 에폭 동안 검증 손실이 개선되지 않아 학습을 조기 종료합니다!')\n",
    "        break # 학습 루프 탈출\n",
    "\n",
    "print(\"\\n맞춤형 학습 루프 완료.\")\n",
    "\n",
    "# 학습 결과 시각화는 history 객체가 없으므로, 루프 내에서 값을 직접 저장하거나 TensorBoard 콜백을 사용해야 합니다.\n",
    "# 여기서는 단순화를 위해 시각화 코드는 제외합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a015f1a",
   "metadata": {},
   "source": [
    "# Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2ad630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 모델 평가 시작 ---\n",
      "입력: 영화 볼만한 거 추천해줘.\n",
      "챗봇 응답: 최신 영화가 좋을 것 같아요.\n",
      "--------------------\n",
      "입력: 오늘 날씨 어때?\n",
      "챗봇 응답: 날씨 어플에 물어보세요.\n",
      "--------------------\n",
      "입력: 너무 피곤하다.\n",
      "챗봇 응답: 아무래도 사생활이 적으니까요.\n",
      "--------------------\n",
      "입력: 배고픈데 뭐 먹을까?\n",
      "챗봇 응답: 맛있는 거 드세요.\n",
      "--------------------\n",
      "입력: 안녕하세요\n",
      "챗봇 응답: 안녕하세요.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate(sentence):\n",
    "    # 1. 입력 문장 전처리 (토큰화, 정수 인코딩, SOS/EOS 토큰 추가는 predict 함수에서 처리)\n",
    "    # 여기서는 이미 인코딩된 시퀀스를 받는다고 가정하거나, predict 함수 내에서 처리\n",
    "\n",
    "    # 2. 입력 시퀀스 생성 (SOS 토큰으로 시작)\n",
    "    # 입력 문장은 인코더 입력으로 사용됨\n",
    "    encoder_input = tf.expand_dims(sentence, 0) # 배치 차원 추가\n",
    "\n",
    "    # 디코더 입력은 START_TOKEN으로 시작\n",
    "    decoder_input = [START_TOKEN]\n",
    "    output = tf.expand_dims(decoder_input, 0) # 배치 차원 추가\n",
    "\n",
    "    # 3. 예측 루프 (최대 MAX_LENGTH까지 생성)\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 마스크 생성\n",
    "        enc_padding_mask = create_padding_mask(encoder_input)\n",
    "        # 디코더의 self-attention을 위한 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
    "        # 디코더의 패딩 마스크 (현재까지 생성된 시퀀스 기준)\n",
    "        dec_target_padding_mask = create_padding_mask(output)\n",
    "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        # 인코더-디코더 어텐션을 위한 패딩 마스크\n",
    "        dec_padding_mask = create_padding_mask(encoder_input)\n",
    "\n",
    "        # 모델 예측 (training=False)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False, # 추론 모드\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # 현재 스텝의 예측 결과에서 가장 확률 높은 토큰 선택 (마지막 토큰)\n",
    "        predictions = predictions[:, -1:, :] # (batch_size, 1, vocab_size)\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 END_TOKEN이 예측되면 루프 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN):\n",
    "            break\n",
    "\n",
    "        # 예측된 ID를 디코더 입력(output)에 추가하여 다음 스텝의 입력으로 사용\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # 배치 차원 제거하고 최종 예측 시퀀스 반환 (START_TOKEN 제외)\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "# --- 사용자 입력 처리 및 예측 실행 함수 ---\n",
    "def predict(sentence):\n",
    "    # 1. 입력 문장 전처리 (정제)\n",
    "    sentence = clean_text(sentence) # 이전 단계에서 정의한 clean_text 함수 사용\n",
    "\n",
    "    # 2. 토큰화 및 정수 인코딩\n",
    "    # ★ 중요: 입력 문장도 최대 길이에 맞춰 패딩해야 함 (인코더 입력용)\n",
    "    tokenized_sentence = tokenizer.encode(sentence)\n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [tokenized_sentence], maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    # pad_sequences는 2D 입력을 기대하므로 리스트로 감싸줌 -> 결과는 (1, MAX_LENGTH)\n",
    "\n",
    "    # 3. evaluate 함수 호출하여 예측 수행\n",
    "    # encoder_input[0]을 전달하여 (MAX_LENGTH,) 형태의 1D 텐서로 만듦\n",
    "    predicted_sequence, _ = evaluate(encoder_input[0])\n",
    "\n",
    "    # 4. 예측된 정수 시퀀스를 다시 텍스트로 디코딩\n",
    "    # START_TOKEN과 END_TOKEN은 결과에서 제외\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in predicted_sequence if i < START_TOKEN] # START/END 토큰 ID 이후의 값 필터링\n",
    "    )\n",
    "\n",
    "    print(f'입력: {sentence}')\n",
    "    print(f'챗봇 응답: {predicted_sentence}')\n",
    "\n",
    "    return predicted_sentence\n",
    "\n",
    "# --- 모델 평가 실행 ---\n",
    "# 몇 가지 예시 문장으로 챗봇 응답 생성 테스트\n",
    "print(\"\\n--- 모델 평가 시작 ---\")\n",
    "predict(\"영화 볼만한 거 추천해줘.\")\n",
    "print(\"-\" * 20)\n",
    "predict(\"오늘 날씨 어때?\")\n",
    "print(\"-\" * 20)\n",
    "predict(\"너무 피곤하다.\")\n",
    "print(\"-\" * 20)\n",
    "predict(\"배고픈데 뭐 먹을까?\")\n",
    "print(\"-\" * 20)\n",
    "predict(\"안녕하세요\") # 학습 데이터에 없을 법한 인사\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fade6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
